{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch With Examples.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhtwA33LAiXtmagMwqoZrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasin-abrar/Machine-Learning/blob/master/PyTorch_With_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ60N_VA2rde"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "\n",
        "N, D_in, H, D_out = 64,1000, 100, 10\n",
        "\n",
        "x = torch.randn(N, D_in, dtype = torch.float)\n",
        "y = torch.randn(N, D_out, dtype = torch.float)\n",
        "\n",
        "w1 = torch.randn(D_in, H, dtype=torch.float, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, dtype=torch.float, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYFrfE2e4L0B",
        "outputId": "0c955c43-93ae-41e2-f6a9-d1c6b59e9caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "lr = 1e-06\n",
        "for t in range(500):\n",
        "  y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
        "  loss = (y_pred-y).pow(2).sum()\n",
        "  if t%100 == 99:\n",
        "    print(t, loss.item())\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w1 -= w1.grad * lr\n",
        "    w2 -= w2.grad * lr\n",
        "    w1.grad.zero_()\n",
        "    w2.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 427.8204345703125\n",
            "199 1.4477845430374146\n",
            "299 0.007437020540237427\n",
            "399 0.0001636559027247131\n",
            "499 3.0194940336514264e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrx8cJRrZtqt",
        "outputId": "c7cbe8d0-efbf-4549-c487-3e22daa50aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in,H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H,D_out)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "lr = 1e-4\n",
        "\n",
        "for t in range(500):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if t%100 == 99:\n",
        "    print(t,loss.item())\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    for p in model.parameters():\n",
        "      p -= lr* p.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.1339709758758545\n",
            "199 0.040574491024017334\n",
            "299 0.0021189232356846333\n",
            "399 0.00018646045646164566\n",
            "499 2.118137854267843e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgZdZdY-bjiX",
        "outputId": "3759f3f0-118b-4057-ce3d-048a8c2bd87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.254732131958008\n",
            "199 0.029007570818066597\n",
            "299 0.0006673292955383658\n",
            "399 1.8868460756493732e-05\n",
            "499 5.926103767706081e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZCXRj7aLlpi",
        "outputId": "7c09ec77-cf9e-4abe-d040-4d60704d0a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H,D_out)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "lr = 1e-04\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "for t in range(500):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y)\n",
        "  if t%100 == 99:\n",
        "    print(t, loss.item())\n",
        "  # model.zero_grad()\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 49.26458740234375\n",
            "199 0.6833275556564331\n",
            "299 0.005712901242077351\n",
            "399 2.1785253920825198e-05\n",
            "499 2.5647281631790975e-08\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}