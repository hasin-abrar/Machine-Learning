{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM TargetChanged PoemGeneratorSeq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MIfvWmo4RKVoypS3_vW1pcNnc39gt6ye",
      "authorship_tag": "ABX9TyNj8Z/Cks8Wyk4LDcRNZTx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasin-abrar/Machine-Learning/blob/master/LSTM_TargetChanged_PoemGeneratorSeq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGU-WV_opIT",
        "outputId": "eb034632-466d-44ec-9866-b7ba28a2f055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "!pip install bcolz\n",
        "import bcolz\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "main_directory = '/content/drive/My Drive/Colab Notebooks/PyTorch Practice/Data/'\n",
        "glove_path = main_directory+\"EncodingVector/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.5)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2668660 sha256=f8ba3c9e57c8c0d4da5bf53ed43f9c1bd6d80e7b5fdc4c5805f40616d406792e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfmPkcz6o69N"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Words:\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyL2NesEpO5x"
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzE22KkGp-fz"
      },
      "source": [
        "MAX_LENGTH = 15\n",
        "def filterLine(line):\n",
        "  return len(line.split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterLines(lines):\n",
        "  return [line for line in lines if filterLine(line)]\n",
        "\n",
        "def indexesFromSentence(words, sentence):\n",
        "  return [words.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(words, sentence):\n",
        "  indexes = indexesFromSentence(words, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def GetInputWordsTensors():\n",
        "  df = pd.read_csv(main_directory+\"PoemDataset/kaggle_poem_dataset.csv\")\n",
        "  william_poems = df[df[\"Author\"] == \"William Shakespeare\"]\n",
        "  # print(william_poems.iloc[33, 4].split('\\n')[:4])\n",
        "  df = william_poems\n",
        "  poems = \"\\n\".join(df.iloc[:, 4].values)\n",
        "  lines = [normalizeString(p) for p in poems.split('\\n')]\n",
        "  lines = filterLines(lines)\n",
        "  input_tensors = []\n",
        "  target_tensors = []\n",
        "  input_words = Words()\n",
        "  input_words.addSentence(lines[0])\n",
        "  input_tensors.append(tensorFromSentence(input_words, lines[0]))\n",
        "  for i in range(1,len(lines)-1):\n",
        "    input_words.addSentence(lines[i])\n",
        "    input_tensors.append(tensorFromSentence(input_words, lines[i]))\n",
        "    target_tensors.append(tensorFromSentence(input_words, lines[i]))\n",
        "  input_words.addSentence(lines[len(lines)-1])\n",
        "  target_tensors.append(tensorFromSentence(input_words, lines[len(lines)-1]))\n",
        "  print('Word Count: %d'%(input_words.n_words))\n",
        "  return input_words, input_tensors, target_tensors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW5UkNOQtJna",
        "outputId": "124b4006-2938-4f31-b614-bc1965fa4ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_words, input_tensors, target_tensors = GetInputWordsTensors()\n",
        "print(len(input_tensors))\n",
        "print(len(target_tensors))\n",
        "# print(input_words.word2count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "let the bird of loudest lay\n",
            "Word Count: 4116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vp4bOmjM4Cd"
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "\n",
        "glove_path = main_directory+\"EncodingVector/\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.50.dat', mode='w')\n",
        "\n",
        "with open(f'{glove_path}/glove.6B.50d.txt', 'rb') as f:\n",
        "  for l in f:\n",
        "    line = l.decode().split()\n",
        "    word = line[0]\n",
        "    words.append(word)\n",
        "    word2idx[word] = idx\n",
        "    idx += 1\n",
        "    vect = np.array(line[1:]).astype(np.float)\n",
        "    vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 50)), rootdir=f'{glove_path}/6B.50.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'{glove_path}/6B.50_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'{glove_path}/6B.50_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3npsIYoNR0G"
      },
      "source": [
        "vectors = bcolz.open(f'{glove_path}/6B.50.dat')[:]\n",
        "words = pickle.load(open(f'{glove_path}/6B.50_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'{glove_path}/6B.50_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vd7pJFJwyPG"
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "\n",
        "glove_path = main_directory+\"EncodingVector/\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.200.dat', mode='w')\n",
        "\n",
        "with open(f'{glove_path}/glove.6B.200d.txt', 'rb') as f:\n",
        "  for l in f:\n",
        "    line = l.decode().split()\n",
        "    word = line[0]\n",
        "    words.append(word)\n",
        "    word2idx[word] = idx\n",
        "    idx += 1\n",
        "    vect = np.array(line[1:]).astype(np.float)\n",
        "    vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 200)), rootdir=f'{glove_path}/6B.200.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'{glove_path}/6B.200_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'{glove_path}/6B.200_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZQaa0_u1BNb"
      },
      "source": [
        "vectors = bcolz.open(f'{glove_path}/6B.200.dat')[:]\n",
        "words = pickle.load(open(f'{glove_path}/6B.200_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'{glove_path}/6B.200_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ9ucfZR7r_h",
        "outputId": "2f922e0c-d427-40a5-a5a0-78cfc652c944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove['the'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.071549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M7weiRzfdyg",
        "outputId": "8fd06df8-a39c-47a0-9291-c16a5bdd1980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_vocab = [input_words.index2word[i] for i in range(input_words.n_words)]\n",
        "print(len(target_vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnAISO0ye_i7",
        "outputId": "c6f4c915-4e8d-4419-bae3-694783949ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matrix_len = len(target_vocab)\n",
        "emb_dim = 200\n",
        "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
        "\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(target_vocab):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.zeros((emb_dim, ))\n",
        "weights_matrix = torch.from_numpy(weights_matrix).to(device)\n",
        "print(words_found)        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAuSPQwSgYjo"
      },
      "source": [
        "\n",
        "def CreateEmbLayer(weights_matrix, non_trainable=False):\n",
        "  num_embeddings, embedding_dim = weights_matrix.size()\n",
        "  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "  emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "  if non_trainable:\n",
        "    emb_layer.weight.requires_grad = False\n",
        "  return emb_layer, embedding_dim\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, weights_matrix, nlayers=2):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = nlayers\n",
        "\n",
        "    self.embedding, self.embedding_dim = CreateEmbLayer(weights_matrix, non_trainable=False)\n",
        "    self.LSTM = nn.LSTM(self.embedding_dim, self.hidden_size,num_layers=self.num_layers)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    # print(hidden.size())\n",
        "    output, (hidden,cell) = self.LSTM(output, (hidden,cell))\n",
        "    return output, hidden, cell\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "  \n",
        "  def initCellState(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, weights_matrix,nlayers=2):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = nlayers\n",
        "\n",
        "    self.embedding, self.embedding_dim = CreateEmbLayer(weights_matrix, non_trainable=False)\n",
        "    self.LSTM = nn.LSTM(self.embedding_dim, self.hidden_size,num_layers=self.num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, (hidden, cell) = self.LSTM(output, (hidden,cell))\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden, cell\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "  \n",
        "  def initCellState(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_taHaijW4w"
      },
      "source": [
        "teacher_forcing_ratio = 0\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  encoder_cell = encoder.initCellState()\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "\n",
        "  # encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "        input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "    # encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_cell = encoder_cell\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "        decoder_input, decoder_hidden, decoder_cell)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "  else:\n",
        "      # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "        decoder_input, decoder_hidden, decoder_cell)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9bitIXUmfI2"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s -= m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh3D09YWmkrc"
      },
      "source": [
        "from datetime import datetime\n",
        "def trainIters(encoder, decoder, n_iters, model_name, print_every=5, plot_every=5, save_every=5, learning_rate=0.01):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "  current_avg_loss = 100\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for iter in range(1, n_iters + 1):\n",
        "    for i in range(len(input_tensors)):\n",
        "      input_tensor = input_tensors[i]\n",
        "      target_tensor = target_tensors[i]\n",
        "\n",
        "      loss = train(input_tensor, target_tensor, encoder,\n",
        "                decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "      print_loss_total += loss\n",
        "      plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / (print_every*len(input_tensors))\n",
        "      \n",
        "      now = datetime.now()\n",
        "      current_time = now.strftime(\"%H:%M:%S\")\n",
        "      print('Current Time: %s ~ %s (%d %d%%) AVG: %.4f Total: %0.4f' % (current_time, timeSince(start, iter / n_iters),\n",
        "                                iter, iter / n_iters * 100, print_loss_avg, print_loss_total))\n",
        "      if print_loss_avg < current_avg_loss:\n",
        "        torch.save(encoder.state_dict(), main_directory+'SavedPoemModels/enc_best_'+model_name)\n",
        "        torch.save(decoder.state_dict(), main_directory+'SavedPoemModels/dec_best_'+model_name)\n",
        "        current_avg_loss = print_loss_avg\n",
        "      print_loss_total = 0\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / (plot_every*len(input_tensors))\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "    \n",
        "    if iter % save_every == 0:\n",
        "      torch.save(encoder.state_dict(), main_directory+'SavedPoemModels/enc_'+model_name)\n",
        "      torch.save(decoder.state_dict(), main_directory+'SavedPoemModels/dec_'+model_name)\n",
        "      \n",
        "    \n",
        "\n",
        "  showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-veZBPqQpJQa",
        "outputId": "00f1bbf3-5ff9-4af9-c90a-d46c1c3655ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        }
      },
      "source": [
        "hidden_size = 200\n",
        "\n",
        "encoder = EncoderRNN(input_words.n_words, hidden_size, weights_matrix).to(device)\n",
        "decoder = DecoderRNN(hidden_size, input_words.n_words, weights_matrix).to(device)\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "model_name= 'h200_ep_200.pt'\n",
        "print('Started Training at : %s'%(current_time))\n",
        "trainIters(encoder, decoder, 200,model_name, print_every=5, plot_every=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started Training at : 08:43:52\n",
            "Current Time: 08:47:36 ~ 3m 43s (- 145m 33s) (5 2%) AVG: 6.8319 Total: 107841.2808\n",
            "Current Time: 08:51:24 ~ 7m 31s (- 143m 2s) (10 5%) AVG: 7.3035 Total: 115285.8800\n",
            "Current Time: 08:55:22 ~ 11m 30s (- 141m 51s) (15 7%) AVG: 7.8901 Total: 124544.9902\n",
            "Current Time: 08:59:22 ~ 15m 30s (- 139m 32s) (20 10%) AVG: 7.8864 Total: 124487.2924\n",
            "Current Time: 09:02:47 ~ 18m 55s (- 132m 25s) (25 12%) AVG: 6.0996 Total: 96282.8933\n",
            "Current Time: 09:06:14 ~ 22m 21s (- 126m 43s) (30 15%) AVG: 6.4847 Total: 102360.8448\n",
            "Current Time: 09:09:38 ~ 25m 46s (- 121m 30s) (35 17%) AVG: 6.3759 Total: 100644.0487\n",
            "Current Time: 09:13:00 ~ 29m 8s (- 116m 33s) (40 20%) AVG: 6.2862 Total: 99228.1963\n",
            "Current Time: 09:16:10 ~ 32m 18s (- 111m 15s) (45 22%) AVG: 5.6230 Total: 88759.7399\n",
            "Current Time: 09:19:28 ~ 35m 36s (- 106m 49s) (50 25%) AVG: 6.0810 Total: 95988.8599\n",
            "Current Time: 09:22:44 ~ 38m 52s (- 102m 28s) (55 27%) AVG: 5.9089 Total: 93271.5416\n",
            "Current Time: 09:25:58 ~ 42m 6s (- 98m 14s) (60 30%) AVG: 5.7987 Total: 91532.5049\n",
            "Current Time: 09:29:37 ~ 45m 44s (- 95m 0s) (65 32%) AVG: 6.8475 Total: 108088.3793\n",
            "Current Time: 09:33:01 ~ 49m 8s (- 91m 16s) (70 35%) AVG: 6.2048 Total: 97942.9695\n",
            "Current Time: 09:36:29 ~ 52m 37s (- 87m 42s) (75 37%) AVG: 6.3239 Total: 99822.3515\n",
            "Current Time: 09:39:41 ~ 55m 49s (- 83m 43s) (80 40%) AVG: 5.4024 Total: 85276.9508\n",
            "Current Time: 09:42:59 ~ 59m 7s (- 79m 59s) (85 42%) AVG: 5.8320 Total: 92057.6067\n",
            "Current Time: 09:46:18 ~ 62m 26s (- 76m 18s) (90 45%) AVG: 5.8524 Total: 92380.7115\n",
            "Current Time: 09:49:38 ~ 65m 46s (- 72m 41s) (95 47%) AVG: 5.8378 Total: 92149.1875\n",
            "Current Time: 09:52:54 ~ 69m 2s (- 69m 2s) (100 50%) AVG: 5.6360 Total: 88964.0021\n",
            "Current Time: 09:56:21 ~ 72m 29s (- 65m 35s) (105 52%) AVG: 6.1176 Total: 96567.0485\n",
            "Current Time: 09:59:40 ~ 75m 48s (- 62m 1s) (110 55%) AVG: 5.8002 Total: 91555.4331\n",
            "Current Time: 10:02:56 ~ 79m 4s (- 58m 26s) (115 57%) AVG: 5.6872 Total: 89772.2020\n",
            "Current Time: 10:06:13 ~ 82m 21s (- 54m 54s) (120 60%) AVG: 5.7426 Total: 90647.4051\n",
            "Current Time: 10:09:22 ~ 85m 30s (- 51m 18s) (125 62%) AVG: 5.3986 Total: 85217.6010\n",
            "Current Time: 10:12:39 ~ 88m 47s (- 47m 48s) (130 65%) AVG: 5.8317 Total: 92053.6111\n",
            "Current Time: 10:15:52 ~ 91m 59s (- 44m 17s) (135 67%) AVG: 5.6012 Total: 88415.6699\n",
            "Current Time: 10:19:03 ~ 95m 11s (- 40m 47s) (140 70%) AVG: 5.5954 Total: 88323.3563\n",
            "Current Time: 10:22:21 ~ 98m 29s (- 37m 21s) (145 72%) AVG: 5.9214 Total: 93469.1370\n",
            "Current Time: 10:25:41 ~ 101m 48s (- 33m 56s) (150 75%) AVG: 5.9242 Total: 93512.8859\n",
            "Current Time: 10:28:56 ~ 105m 4s (- 30m 30s) (155 77%) AVG: 5.7339 Total: 90510.3965\n",
            "Current Time: 10:32:12 ~ 108m 20s (- 27m 5s) (160 80%) AVG: 5.8664 Total: 92600.7493\n",
            "Current Time: 10:35:29 ~ 111m 36s (- 23m 40s) (165 82%) AVG: 5.8555 Total: 92429.0955\n",
            "Current Time: 10:38:42 ~ 114m 50s (- 20m 15s) (170 85%) AVG: 5.7614 Total: 90943.4909\n",
            "Current Time: 10:41:56 ~ 118m 4s (- 16m 52s) (175 87%) AVG: 5.7503 Total: 90768.1075\n",
            "Current Time: 10:45:15 ~ 121m 23s (- 13m 29s) (180 90%) AVG: 6.0070 Total: 94821.2509\n",
            "Current Time: 10:48:36 ~ 124m 44s (- 10m 6s) (185 92%) AVG: 6.0385 Total: 95317.6872\n",
            "Current Time: 10:52:03 ~ 128m 11s (- 6m 44s) (190 95%) AVG: 6.3556 Total: 100322.8599\n",
            "Current Time: 10:55:17 ~ 131m 24s (- 3m 22s) (195 97%) AVG: 5.7568 Total: 90871.5235\n",
            "Current Time: 10:58:31 ~ 134m 39s (- 0m 0s) (200 100%) AVG: 5.7116 Total: 90157.7386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2766bpqOarRP",
        "outputId": "5311d5fe-afd8-4874-f0ab-87ec9488af11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "import time\n",
        "\n",
        "t = time.localtime()\n",
        "current_time = time.strftime(\"%H:%M:%S\", t)\n",
        "print('Current time: %s'%(current_time) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current time: 07:54:17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUq24qN2hm_Q",
        "outputId": "356fdd41-c8af-479c-c148-149e71e291a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def GetFileChar():\n",
        "  file = open(main_directory+'break.txt')\n",
        "  lines = file.readlines()\n",
        "  return lines[0].strip()\n",
        "\n",
        "q = GetFileChar()\n",
        "if q == 'c':\n",
        "  print('as')\n",
        "else:\n",
        "  print(q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw95yiFMRLh6"
      },
      "source": [
        "def GetEncodedVector(encoder, sentence):\n",
        "  with torch.no_grad():\n",
        "    sentence_tensor = tensorFromSentence(input_words, sentence)\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initCellState()\n",
        "    input_length = sentence_tensor.size(0)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          sentence_tensor[ei], encoder_hidden, encoder_cell)\n",
        "  return encoder_hidden, encoder_cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHM3Ix5cnGqy"
      },
      "source": [
        "def evaluate(decoder, context_hid, context_cell, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "    decoder_hidden = context_hid\n",
        "    decoder_cell = context_cell\n",
        "\n",
        "    decoded_words = []\n",
        "    # decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell)\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      if topi.item() == EOS_token or topi.item() == SOS_token:\n",
        "        # decoded_words.append('EOS')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(input_words.index2word[topi.item()])\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZwC79Ckt1iQ"
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def GetContext(encoder, sentences, query_word):\n",
        "  qw_hidden,qw_cell = GetEncodedVector(encoder, query_word)\n",
        "  if sentences == []:\n",
        "    return qw_hidden, qw_cell\n",
        "  qw_hidden = qw_hidden.cpu().numpy()\n",
        "  qw_cell = qw_cell.cpu().numpy()\n",
        "  sen_hiddens = []\n",
        "  sen_cells = []\n",
        "  for sentence in sentences:\n",
        "    sen_hid, sen_cell = GetEncodedVector(encoder, sentence)\n",
        "    sen_hiddens.append(sen_hid.cpu().numpy() )\n",
        "    sen_cells.append(sen_cell.cpu().numpy() )\n",
        "  sen_hiddens = np.array(sen_hiddens)\n",
        "  sen_cells = np.array(sen_cells)\n",
        "  weights_hid = []\n",
        "  weights_cell = []\n",
        "  for sen_hidden in sen_hiddens:\n",
        "    # print(type())\n",
        "    dist = spatial.distance.cosine(sen_hidden, qw_hidden)\n",
        "    weights_hid.append(np.array([dist]))\n",
        "  for sen_cell in sen_cells:\n",
        "    dist = spatial.distance.cosine(sen_cell, qw_cell)\n",
        "    weights_cell.append(np.array([dist]))\n",
        "\n",
        "  weights_hid = np.array(weights_hid/max(weights_hid)).reshape(-1,1,1,1)\n",
        "  weights_cell = np.array(weights_cell/max(weights_cell)).reshape(-1,1,1,1)\n",
        "  # print(sen_hiddens.shape)\n",
        "  context_hid = np.average(weights_hid * sen_hiddens, axis = 0)\n",
        "  context_cell = np.average(weights_cell * sen_cells, axis = 0)\n",
        "  # print(weights.shape)\n",
        "  # print(context.shape)\n",
        "  context_hid = torch.from_numpy(context_hid).to(device)\n",
        "  context_cell = torch.from_numpy(context_cell).to(device)\n",
        "  # print(context.size())\n",
        "  return context_hid, context_cell\n",
        "\n",
        "def GetContext_P(sequences, query_word):\n",
        "  qw_embed = weights_matrix[input_words.word2index[query_word]].cpu().numpy()\n",
        "  if sequences == []:\n",
        "    return qw_embed\n",
        "  seq_embeddings = []\n",
        "  for sequence in sequences:\n",
        "    seq_embed = np.zeros((1, emb_dim))\n",
        "    sequence = sequence.split(' ')\n",
        "    for word in sequence:\n",
        "      seq_embed += weights_matrix[input_words.word2index[word]].cpu().numpy()\n",
        "    seq_embeddings.append(seq_embed)\n",
        "  seq_embeddings = np.array(seq_embeddings)\n",
        "  \n",
        "  weights = []\n",
        "  for seq_embed in seq_embeddings:\n",
        "      # get the distance between the query word and the sentence embeddings\n",
        "      print(seq_embed.shape)\n",
        "      print(qw_embed.shape)\n",
        "      dist = spatial.distance.cosine(seq_embed, qw_embed)\n",
        "      weights.append(np.array([dist]))\n",
        "      \n",
        "  # normalize the distances\n",
        "  weights = np.array(weights/max(weights))\n",
        "      \n",
        "  # get the final weighted context\n",
        "  context = sum(weights * seq_embeddings)\n",
        "  context = torch.from_numpy(context).to(device)\n",
        "  print(type(context))\n",
        "  return context\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7xd5qrxojL6",
        "outputId": "34210fc9-de6f-4650-8594-f122b5de041c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def GeneratePoem(encoder, decoder, query_word, nLines=10):\n",
        "  output_sentences = []\n",
        "  for i in range(nLines):\n",
        "      context_hid, context_cell = GetContext(encoder, output_sentences[-5:], query_word)\n",
        "      # context = torch.from_numpy(context).to(device)\n",
        "      # print(type(context))\n",
        "      output_words = evaluate(decoder, context_hid, context_cell)\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      output_sentences.append(output_sentence)\n",
        "      print(output_sentence)\n",
        "\n",
        "hidden_size = 200\n",
        "\n",
        "encoder = EncoderRNN(input_words.n_words, hidden_size, weights_matrix).to(device)\n",
        "decoder = DecoderRNN(hidden_size, input_words.n_words, weights_matrix).to(device)\n",
        "model_name= 'h200_ep_200.pt'\n",
        "\n",
        "encoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/enc_'+model_name))\n",
        "decoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/dec_'+model_name))\n",
        "\n",
        "GeneratePoem(encoder, decoder, 'limb')      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35785d0e9ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'h200_ep_200.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EncoderRNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Oqa_VZuQr1",
        "outputId": "e641c585-fc86-455f-d753-df96253b5cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sequences = ['sky', 'sky love']\n",
        "query_word = 'love'\n",
        "context = GetContext(encoder, sequences, query_word)\n",
        "print(type(context))\n",
        "print(context.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 1, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNFtrux2aM4d",
        "outputId": "abd660f8-8674-4070-f90b-5d4c0111cef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "w = np.array([[1],[2]])\n",
        "w = np.array(w/max(w))\n",
        "w = np.reshape(w,(-1,1,1,1))\n",
        "print(w.shape)\n",
        "print(w)\n",
        "q = np.ones((2,1,1,3))\n",
        "print(q)\n",
        "print(w.shape)\n",
        "result = np.multiply(w,q)\n",
        "print(result.shape)\n",
        "print(result)\n",
        "result = np.average(w*q,axis = 0)\n",
        "print(\"\\nResult:\")\n",
        "# print(result)\n",
        "print(result.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bfdc18b96cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtvS7reOr1DT",
        "outputId": "1208a7ec-04f4-4ce4-86db-6c6e39276f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = [1,2,3,4,5,6,7]\n",
        "print(s[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdrlGZY9yFNq",
        "outputId": "a68fddae-6e14-45d7-bb24-2a0480c2d20d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "start_sentence = \"From fairest creatures we\"\n",
        "GeneratePoem(encoder, decoder, normalizeString(start_sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from fairest creatures we\n",
            "we fear we rich we ever fear breast breast breast\n",
            "pluck fed fed whereupon pluck or fed ?\n",
            "to makes makes to breach to makes .\n",
            "to wail to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHlbnKwwjkXd"
      },
      "source": [
        "def get_context(sequences, query_word):\n",
        "  \"\"\"\n",
        "    This function takes as input multiple lines generated by the model so far and a query_word or the theme of the poem.\n",
        "    \n",
        "    So, the approach is we will add the embeddings of all the words in a sentence to get the sentence embeddings and will\n",
        "    create the sentence embeddings for all the sentences created so far.\n",
        "    \n",
        "    Now, to summarize all the sentence embeddings into a single vector, we will calculate the distance of all the sentence\n",
        "    from the query_word. These weights are normalized and will be used as the weights to combine the sentence embeddings.\n",
        "    \n",
        "    This final embedding vector or the context will be passed to the Decoder as a hidden state and a new line is generated from it.\n",
        "  \"\"\"\n",
        "  \n",
        "  assert query_word in sg_obj.word2idx\n",
        "  \n",
        "  # null vector containing all zeroes\n",
        "  query_word_embed = sg_obj.word2vec.get(query_word, np.zeros(shape=(EMBEDDING_DIM)))\n",
        "  \n",
        "  if sequences == []:\n",
        "      return query_word_embed\n",
        "  \n",
        "  # to keep all the sentence embeddings\n",
        "  seq_embeddings = []\n",
        "  for seq in sequences:  \n",
        "    # add up all the word embeddings of a sequence\n",
        "    zero_vector = np.zeros(shape=(EMBEDDING_DIM))\n",
        "    for word in seq:\n",
        "        zero_vector += sg_obj.word2vec.get(word, np.zeros(shape=(EMBEDDING_DIM)))\n",
        "    seq_embeddings.append(zero_vector)\n",
        "  seq_embeddings = np.array(seq_embeddings)\n",
        "          \n",
        "  weights = []\n",
        "  for seq_embed in seq_embeddings:\n",
        "      # get the distance between the query word and the sentence embeddings\n",
        "      dist = spatial.distance.cosine(seq_embed, query_word_embed)\n",
        "      weights.append(np.array([dist]))\n",
        "      \n",
        "  # normalize the distances\n",
        "  weights = np.array(weights/max(weights))\n",
        "      \n",
        "  # get the final weighted context\n",
        "  context = sum(weights * seq_embeddings)\n",
        "  \n",
        "  return context\n",
        "\n",
        "def get_sample_line(context):\n",
        "  \"\"\"\n",
        "      Get a single line using the provided context as a hidden state\n",
        "      \n",
        "      Parameters:\n",
        "          context (np.array): generated context of the same size as the word_embedding\n",
        "  \"\"\"\n",
        "  \n",
        "  # sentence start token\n",
        "  sos_token = np.array([[sg_obj.word2idx.get(\"<sos>\")]])\n",
        "  \n",
        "  # create the empty lstm state vectors\n",
        "  h = np.array([context])    \n",
        "  c = np.zeros(shape=(1, LATENT_DIM))\n",
        "  \n",
        "  # so we know when to quit\n",
        "  eos_token = sg_obj.word2idx['<eos>']\n",
        "  \n",
        "  output_sequence = []\n",
        "  \n",
        "  # limit the length of the generated line\n",
        "  for i in range(sg_obj.MAX_SEQ_LEN):\n",
        "      \n",
        "      # predict the first word\n",
        "      # the outputed stated are passed to the lstm to generate the next word in the sequence\n",
        "      o, h, c = Decoder.predict([sos_token, h, c])\n",
        "      \n",
        "      # get the probabilities generated from the dense layer\n",
        "      probs = o[0,0]\n",
        "      \n",
        "      if np.argmax(probs) ==0:\n",
        "          print(\"Something went wrong!!\")\n",
        "      \n",
        "      probs = np.nan_to_num(probs)\n",
        "      # the word-indices starts from 1 so 1st value does not count\n",
        "      probs[0] = 0 \n",
        "      \n",
        "      # normalize the probabilities\n",
        "      probs /= probs.sum()\n",
        "      \n",
        "      # select a random word with provided probability of being selected\n",
        "      selected_idx = np.random.choice(len(probs), p=probs)\n",
        "      \n",
        "      # if the generated word is equal to eos_token, terminate\n",
        "      if selected_idx == eos_token:\n",
        "          break\n",
        "      \n",
        "      # append the generated word to the output_sequence\n",
        "      output_sequence.append(sg_obj.idx2word.get(selected_idx, \"Error <%d>\" % selected_idx))\n",
        "      \n",
        "      # the word generated will be used as an input to generated the new word\n",
        "      sos_token[0][0] = selected_idx\n",
        "  \n",
        "  # return the sequence\n",
        "  return output_sequence    \n",
        "\n",
        "################### MAIN ################\n",
        "# the theme of the poem - only single word (for simplicity)\n",
        "query_word = \"love\"\n",
        "\n",
        "# to append the generated poem lines\n",
        "poem_lines = []\n",
        "\n",
        "# first sequence containing only ones, this will be used to generate the context\n",
        "sequences = []\n",
        "\n",
        "# we will be generating 8 lines, you can play around with this\n",
        "for line_no in range(8):\n",
        "    \n",
        "    # get the context, for the first line the context will contain the embeddings of the theme words itself\n",
        "    context = get_context(sequences, query_word)\n",
        "    \n",
        "    try:\n",
        "        # generate a new line and append it\n",
        "        sequences.append(get_sample_line(context))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    poem_lines.append(\" \".join(sequences[-1]))\n",
        "    \n",
        "print(\"\\n\\n\")\n",
        "print(\"\\n\".join(poem_lines))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBxtT-N_z4OO"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRHxZ3UgoSck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}