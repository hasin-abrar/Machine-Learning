{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM PoemGeneratorSeq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MIfvWmo4RKVoypS3_vW1pcNnc39gt6ye",
      "authorship_tag": "ABX9TyOHYiDG5mXBiapbBg7KJRqk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasin-abrar/Machine-Learning/blob/master/LSTM_PoemGeneratorSeq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGU-WV_opIT",
        "outputId": "e4aaac81-3638-44d7-d852-3a3db6436cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "!pip install bcolz\n",
        "import bcolz\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "main_directory = '/content/drive/My Drive/Colab Notebooks/PyTorch Practice/Data/'\n",
        "glove_path = main_directory+\"EncodingVector/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.18.5)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp36-cp36m-linux_x86_64.whl size=2662225 sha256=b0fb5211958d30385b4a08f1a3f1ce7e8ea75a0c34f8172b10a073adbade1f4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfmPkcz6o69N"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Words:\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyL2NesEpO5x"
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "    c for c in unicodedata.normalize('NFD', s)\n",
        "    if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzE22KkGp-fz"
      },
      "source": [
        "MAX_LENGTH = 15\n",
        "def filterLine(line):\n",
        "  return len(line.split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterLines(lines):\n",
        "  return [line for line in lines if filterLine(line)]\n",
        "\n",
        "def indexesFromSentence(words, sentence):\n",
        "  return [words.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(words, sentence):\n",
        "  indexes = indexesFromSentence(words, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def GetInputWordsTensors():\n",
        "  df = pd.read_csv(main_directory+\"PoemDataset/kaggle_poem_dataset.csv\")\n",
        "  william_poems = df[df[\"Author\"] == \"William Shakespeare\"]\n",
        "  # print(william_poems.iloc[33, 4].split('\\n')[:4])\n",
        "  df = william_poems\n",
        "  poems = \"\\n\".join(df.iloc[:, 4].values)\n",
        "  lines = [normalizeString(p) for p in poems.split('\\n')]\n",
        "  lines = filterLines(lines)\n",
        "  input_tensors = []\n",
        "  input_words = Words()\n",
        "  flag = True\n",
        "  for line in lines:\n",
        "    if flag:\n",
        "      print(line)\n",
        "      flag = False\n",
        "    input_words.addSentence(line)\n",
        "    input_tensors.append(tensorFromSentence(input_words, line))\n",
        "  print('Word Count: %d'%(input_words.n_words))\n",
        "  return input_words, input_tensors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW5UkNOQtJna",
        "outputId": "d4c242d5-7e73-4657-a38d-c1e6d9d2b251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_words, input_tensors = GetInputWordsTensors()\n",
        "# print(input_words.word2count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "let the bird of loudest lay\n",
            "Word Count: 4116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vp4bOmjM4Cd"
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "\n",
        "glove_path = main_directory+\"EncodingVector/\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.50.dat', mode='w')\n",
        "\n",
        "with open(f'{glove_path}/glove.6B.50d.txt', 'rb') as f:\n",
        "  for l in f:\n",
        "    line = l.decode().split()\n",
        "    word = line[0]\n",
        "    words.append(word)\n",
        "    word2idx[word] = idx\n",
        "    idx += 1\n",
        "    vect = np.array(line[1:]).astype(np.float)\n",
        "    vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 50)), rootdir=f'{glove_path}/6B.50.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'{glove_path}/6B.50_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'{glove_path}/6B.50_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3npsIYoNR0G"
      },
      "source": [
        "vectors = bcolz.open(f'{glove_path}/6B.50.dat')[:]\n",
        "words = pickle.load(open(f'{glove_path}/6B.50_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'{glove_path}/6B.50_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vd7pJFJwyPG"
      },
      "source": [
        "words = []\n",
        "idx = 0\n",
        "word2idx = {}\n",
        "\n",
        "glove_path = main_directory+\"EncodingVector/\"\n",
        "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.200.dat', mode='w')\n",
        "\n",
        "with open(f'{glove_path}/glove.6B.200d.txt', 'rb') as f:\n",
        "  for l in f:\n",
        "    line = l.decode().split()\n",
        "    word = line[0]\n",
        "    words.append(word)\n",
        "    word2idx[word] = idx\n",
        "    idx += 1\n",
        "    vect = np.array(line[1:]).astype(np.float)\n",
        "    vectors.append(vect)\n",
        "    \n",
        "vectors = bcolz.carray(vectors[1:].reshape((400001, 200)), rootdir=f'{glove_path}/6B.200.dat', mode='w')\n",
        "vectors.flush()\n",
        "pickle.dump(words, open(f'{glove_path}/6B.200_words.pkl', 'wb'))\n",
        "pickle.dump(word2idx, open(f'{glove_path}/6B.200_idx.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZQaa0_u1BNb"
      },
      "source": [
        "vectors = bcolz.open(f'{glove_path}/6B.200.dat')[:]\n",
        "words = pickle.load(open(f'{glove_path}/6B.200_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'{glove_path}/6B.200_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ9ucfZR7r_h",
        "outputId": "b4030f7d-b6d2-433c-ba68-abae1b43001a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove['the'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.071549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M7weiRzfdyg",
        "outputId": "785ada04-41fa-4019-ffae-f3323f8b3fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_vocab = [input_words.index2word[i] for i in range(input_words.n_words)]\n",
        "print(len(target_vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnAISO0ye_i7",
        "outputId": "86bb7ed5-d0c7-4caa-ddcd-6fd66c5e1c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matrix_len = len(target_vocab)\n",
        "emb_dim = 200\n",
        "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
        "\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(target_vocab):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.zeros((emb_dim, ))\n",
        "weights_matrix = torch.from_numpy(weights_matrix).to(device)\n",
        "print(words_found)        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAuSPQwSgYjo"
      },
      "source": [
        "\n",
        "def CreateEmbLayer(weights_matrix, non_trainable=False):\n",
        "  num_embeddings, embedding_dim = weights_matrix.size()\n",
        "  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "  emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "  if non_trainable:\n",
        "    emb_layer.weight.requires_grad = False\n",
        "  return emb_layer, embedding_dim\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, weights_matrix, nlayers=2):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = nlayers\n",
        "\n",
        "    self.embedding, self.embedding_dim = CreateEmbLayer(weights_matrix, non_trainable=False)\n",
        "    self.LSTM = nn.LSTM(self.embedding_dim, self.hidden_size,num_layers=self.num_layers)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    # print(hidden.size())\n",
        "    output, (hidden,cell) = self.LSTM(output, (hidden,cell))\n",
        "    return output, hidden, cell\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "  \n",
        "  def initCellState(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, weights_matrix,nlayers=2):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = nlayers\n",
        "\n",
        "    self.embedding, self.embedding_dim = CreateEmbLayer(weights_matrix, non_trainable=False)\n",
        "    self.LSTM = nn.LSTM(self.embedding_dim, self.hidden_size,num_layers=self.num_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, (hidden, cell) = self.LSTM(output, (hidden,cell))\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden, cell\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "  \n",
        "  def initCellState(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_taHaijW4w"
      },
      "source": [
        "teacher_forcing_ratio = 0\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  encoder_cell = encoder.initCellState()\n",
        "\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "\n",
        "  # encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "        input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "    # encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_cell = encoder_cell\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "        decoder_input, decoder_hidden, decoder_cell)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "  else:\n",
        "      # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "        decoder_input, decoder_hidden, decoder_cell)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Dd1hzThKaH",
        "outputId": "71302e28-7cca-4372-b17d-1c88a8a2bd8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "y_pred = torch.tensor([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
        "y_true = torch.tensor([1, 2])  \n",
        "m = nn.LogSoftmax(dim=1)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "print(torch.log(y_pred))   \n",
        "print(m(y_pred))                   \n",
        "print(nn.NLLLoss()(m(y_pred), y_true))  \n",
        "print(nn.NLLLoss()(y_pred, y_true))                                                                                                                 \n",
        "print(nn.NLLLoss()(torch.log(y_pred), y_true))\n",
        "print(loss(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.9957, -0.0513,    -inf],\n",
            "        [-2.3026, -0.2231, -2.3026]])\n",
            "tensor([[-1.4841, -0.5841, -1.5341],\n",
            "        [-1.3897, -0.6897, -1.3897]])\n",
            "tensor(0.9869)\n",
            "tensor(-0.5250)\n",
            "tensor(1.1769)\n",
            "tensor(0.9869)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9bitIXUmfI2"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s -= m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh3D09YWmkrc"
      },
      "source": [
        "from datetime import datetime\n",
        "def trainIters(encoder, decoder, n_iters, model_name, print_every=5, plot_every=5, save_every=5, learning_rate=0.001):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "  current_avg_loss = 100\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for iter in range(1, n_iters + 1):\n",
        "    for it in input_tensors:\n",
        "      input_tensor = it\n",
        "      target_tensor = input_tensor[:]\n",
        "\n",
        "      loss = train(input_tensor, target_tensor, encoder,\n",
        "                decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "      print_loss_total += loss\n",
        "      plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / (print_every*len(input_tensors))\n",
        "      \n",
        "      now = datetime.now()\n",
        "      current_time = now.strftime(\"%H:%M:%S\")\n",
        "      print('Current Time: %s ~ %s (%d %d%%) AVG: %.4f Total: %0.4f' % (current_time, timeSince(start, iter / n_iters),\n",
        "                                iter, iter / n_iters * 100, print_loss_avg, print_loss_total))\n",
        "      if print_loss_avg < current_avg_loss:\n",
        "        torch.save(encoder.state_dict(), main_directory+'SavedPoemModels/enc_best_'+model_name)\n",
        "        torch.save(decoder.state_dict(), main_directory+'SavedPoemModels/dec_best_'+model_name)\n",
        "        current_avg_loss = print_loss_avg\n",
        "      print_loss_total = 0\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / (plot_every*len(input_tensors))\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "    \n",
        "    if iter % save_every == 0:\n",
        "      torch.save(encoder.state_dict(), main_directory+'SavedPoemModels/enc_'+model_name)\n",
        "      torch.save(decoder.state_dict(), main_directory+'SavedPoemModels/dec_'+model_name)\n",
        "      \n",
        "    \n",
        "\n",
        "  showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-veZBPqQpJQa",
        "outputId": "5ce8b436-df91-431c-fc83-de1ab83e63ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "hidden_size = 200\n",
        "\n",
        "encoder = EncoderRNN(input_words.n_words, hidden_size, weights_matrix).to(device)\n",
        "decoder = DecoderRNN(hidden_size, input_words.n_words, weights_matrix).to(device)\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "model_name= 'h200_ep_200_2layer.pt'\n",
        "print('Started Training at : %s'%(current_time))\n",
        "trainIters(encoder, decoder, 200,model_name, print_every=5, plot_every=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started Training at : 08:41:03\n",
            "Current Time: 08:46:51 ~ 5m 47s (- 226m 1s) (5 2%) AVG: 7.9707 Total: 125817.9426\n",
            "Current Time: 08:52:39 ~ 11m 35s (- 220m 20s) (10 5%) AVG: 7.9759 Total: 125900.0616\n",
            "Current Time: 08:58:26 ~ 17m 22s (- 214m 23s) (15 7%) AVG: 7.9741 Total: 125870.6323\n",
            "Current Time: 09:04:14 ~ 23m 11s (- 208m 44s) (20 10%) AVG: 7.9642 Total: 125715.5150\n",
            "Current Time: 09:10:03 ~ 28m 59s (- 202m 58s) (25 12%) AVG: 7.9481 Total: 125460.9802\n",
            "Current Time: 09:15:50 ~ 34m 47s (- 197m 6s) (30 15%) AVG: 7.9336 Total: 125232.2330\n",
            "Current Time: 09:21:39 ~ 40m 36s (- 191m 25s) (35 17%) AVG: 7.9254 Total: 125102.8241\n",
            "Current Time: 09:27:27 ~ 46m 24s (- 185m 37s) (40 20%) AVG: 7.8980 Total: 124669.8516\n",
            "Current Time: 09:33:14 ~ 52m 11s (- 179m 46s) (45 22%) AVG: 7.8779 Total: 124353.0757\n",
            "Current Time: 09:39:02 ~ 57m 59s (- 173m 58s) (50 25%) AVG: 7.8675 Total: 124188.7805\n",
            "Current Time: 09:44:49 ~ 63m 45s (- 168m 6s) (55 27%) AVG: 7.8572 Total: 124026.2074\n",
            "Current Time: 09:50:38 ~ 69m 35s (- 162m 22s) (60 30%) AVG: 7.8477 Total: 123876.3221\n",
            "Current Time: 09:56:31 ~ 75m 28s (- 156m 45s) (65 32%) AVG: 7.8383 Total: 123728.1931\n",
            "Current Time: 10:02:23 ~ 81m 19s (- 151m 2s) (70 35%) AVG: 7.8284 Total: 123571.7002\n",
            "Current Time: 10:08:15 ~ 87m 12s (- 145m 20s) (75 37%) AVG: 7.8223 Total: 123475.4195\n",
            "Current Time: 10:14:05 ~ 93m 2s (- 139m 33s) (80 40%) AVG: 7.8163 Total: 123380.0444\n",
            "Current Time: 10:20:00 ~ 98m 57s (- 133m 52s) (85 42%) AVG: 7.8123 Total: 123316.3753\n",
            "Current Time: 10:26:05 ~ 105m 1s (- 128m 22s) (90 45%) AVG: 7.8084 Total: 123256.3303\n",
            "Current Time: 10:32:10 ~ 111m 7s (- 122m 48s) (95 47%) AVG: 7.8033 Total: 123174.6874\n",
            "Current Time: 10:38:13 ~ 117m 9s (- 117m 9s) (100 50%) AVG: 7.7970 Total: 123076.4014\n",
            "Current Time: 10:44:12 ~ 123m 9s (- 111m 25s) (105 52%) AVG: 7.7886 Total: 122942.7521\n",
            "Current Time: 10:50:07 ~ 129m 4s (- 105m 36s) (110 55%) AVG: 7.7834 Total: 122860.3518\n",
            "Current Time: 10:56:15 ~ 135m 12s (- 99m 56s) (115 57%) AVG: 7.7787 Total: 122786.7507\n",
            "Current Time: 11:02:24 ~ 141m 21s (- 94m 14s) (120 60%) AVG: 7.7733 Total: 122700.9912\n",
            "Current Time: 11:08:30 ~ 147m 26s (- 88m 28s) (125 62%) AVG: 7.7703 Total: 122653.8442\n",
            "Current Time: 11:14:32 ~ 153m 29s (- 82m 38s) (130 65%) AVG: 7.7658 Total: 122583.5332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9FAwwRZHoQa",
        "outputId": "d13f7b7e-312b-4e4c-891b-f9dcc471f7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_tensors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IKxT_8jG8mD",
        "outputId": "9535b680-4fe8-4e35-bdde-da2208a9e31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# pre-trained\n",
        "hidden_size = 200\n",
        "\n",
        "encoder = EncoderRNN(input_words.n_words, hidden_size, weights_matrix).to(device)\n",
        "decoder = DecoderRNN(hidden_size, input_words.n_words, weights_matrix).to(device)\n",
        "model_name= 'h200_ep_200.pt'\n",
        "\n",
        "encoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/enc_'+model_name))\n",
        "decoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/dec_'+model_name))\n",
        "model_name= 'h200_ep_200_pretrained.pt'\n",
        "\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "print('Started Training at : %s'%(current_time))\n",
        "trainIters(encoder, decoder, 200,model_name, print_every=5, plot_every=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started Training at : 06:32:05\n",
            "Current Time: 06:35:09 ~ 3m 3s (- 119m 33s) (5 2%) AVG: 5.7195 Total: 90281.7790\n",
            "Current Time: 06:38:10 ~ 6m 4s (- 115m 25s) (10 5%) AVG: 5.4862 Total: 86599.0423\n",
            "Current Time: 06:41:09 ~ 9m 4s (- 111m 49s) (15 7%) AVG: 5.4259 Total: 85647.8286\n",
            "Current Time: 06:44:16 ~ 12m 10s (- 109m 38s) (20 10%) AVG: 5.8700 Total: 92658.6166\n",
            "Current Time: 06:47:27 ~ 15m 22s (- 107m 34s) (25 12%) AVG: 6.0769 Total: 95924.3841\n",
            "Current Time: 06:50:39 ~ 18m 33s (- 105m 11s) (30 15%) AVG: 6.1270 Total: 96714.0176\n",
            "Current Time: 06:53:46 ~ 21m 40s (- 102m 13s) (35 17%) AVG: 5.8368 Total: 92133.9011\n",
            "Current Time: 06:56:56 ~ 24m 50s (- 99m 23s) (40 20%) AVG: 6.0047 Total: 94784.7729\n",
            "Current Time: 07:00:09 ~ 28m 3s (- 96m 37s) (45 22%) AVG: 6.1453 Total: 97003.4462\n",
            "Current Time: 07:03:20 ~ 31m 14s (- 93m 42s) (50 25%) AVG: 6.0314 Total: 95205.9350\n",
            "Started Training at : 06:32:05\n",
            "Current Time: 06:35:09 ~ 3m 3s (- 119m 33s) (5 2%) AVG: 5.7195 Total: 90281.7790\n",
            "Current Time: 06:38:10 ~ 6m 4s (- 115m 25s) (10 5%) AVG: 5.4862 Total: 86599.0423\n",
            "Current Time: 06:41:09 ~ 9m 4s (- 111m 49s) (15 7%) AVG: 5.4259 Total: 85647.8286\n",
            "Current Time: 06:44:16 ~ 12m 10s (- 109m 38s) (20 10%) AVG: 5.8700 Total: 92658.6166\n",
            "Current Time: 06:47:27 ~ 15m 22s (- 107m 34s) (25 12%) AVG: 6.0769 Total: 95924.3841\n",
            "Current Time: 06:50:39 ~ 18m 33s (- 105m 11s) (30 15%) AVG: 6.1270 Total: 96714.0176\n",
            "Current Time: 06:53:46 ~ 21m 40s (- 102m 13s) (35 17%) AVG: 5.8368 Total: 92133.9011\n",
            "Current Time: 06:56:56 ~ 24m 50s (- 99m 23s) (40 20%) AVG: 6.0047 Total: 94784.7729\n",
            "Current Time: 07:00:09 ~ 28m 3s (- 96m 37s) (45 22%) AVG: 6.1453 Total: 97003.4462\n",
            "Current Time: 07:03:20 ~ 31m 14s (- 93m 42s) (50 25%) AVG: 6.0314 Total: 95205.9350\n",
            "Current Time: 07:06:30 ~ 34m 24s (- 90m 43s) (55 27%) AVG: 6.0441 Total: 95406.6613\n",
            "Current Time: 07:06:30 ~ 34m 24s (- 90m 43s) (55 27%) AVG: 6.0441 Total: 95406.6613\n",
            "Current Time: 07:09:32 ~ 37m 26s (- 87m 21s) (60 30%) AVG: 5.5626 Total: 87804.8977\n",
            "Current Time: 07:09:32 ~ 37m 26s (- 87m 21s) (60 30%) AVG: 5.5626 Total: 87804.8977\n",
            "Current Time: 07:12:39 ~ 40m 33s (- 84m 15s) (65 32%) AVG: 5.8729 Total: 92702.9908\n",
            "Current Time: 07:12:39 ~ 40m 33s (- 84m 15s) (65 32%) AVG: 5.8729 Total: 92702.9908\n",
            "Current Time: 07:15:44 ~ 43m 38s (- 81m 3s) (70 35%) AVG: 5.7256 Total: 90378.3264\n",
            "Current Time: 07:15:44 ~ 43m 38s (- 81m 3s) (70 35%) AVG: 5.7256 Total: 90378.3264\n",
            "Current Time: 07:18:53 ~ 46m 47s (- 77m 59s) (75 37%) AVG: 5.9088 Total: 93270.5995\n",
            "Current Time: 07:18:53 ~ 46m 47s (- 77m 59s) (75 37%) AVG: 5.9088 Total: 93270.5995\n",
            "Current Time: 07:22:01 ~ 49m 55s (- 74m 53s) (80 40%) AVG: 5.8052 Total: 91634.6155\n",
            "Current Time: 07:22:01 ~ 49m 55s (- 74m 53s) (80 40%) AVG: 5.8052 Total: 91634.6155\n",
            "Current Time: 07:25:11 ~ 53m 5s (- 71m 50s) (85 42%) AVG: 5.9406 Total: 93771.7488\n",
            "Current Time: 07:25:11 ~ 53m 5s (- 71m 50s) (85 42%) AVG: 5.9406 Total: 93771.7488\n",
            "Current Time: 07:28:21 ~ 56m 15s (- 68m 46s) (90 45%) AVG: 5.9288 Total: 93586.5167\n",
            "Current Time: 07:28:21 ~ 56m 15s (- 68m 46s) (90 45%) AVG: 5.9288 Total: 93586.5167\n",
            "Current Time: 07:31:30 ~ 59m 24s (- 65m 40s) (95 47%) AVG: 5.9442 Total: 93829.8066\n",
            "Current Time: 07:31:30 ~ 59m 24s (- 65m 40s) (95 47%) AVG: 5.9442 Total: 93829.8066\n",
            "Current Time: 07:34:40 ~ 62m 34s (- 62m 34s) (100 50%) AVG: 5.9814 Total: 94416.0054\n",
            "Current Time: 07:34:40 ~ 62m 34s (- 62m 34s) (100 50%) AVG: 5.9814 Total: 94416.0054\n",
            "Current Time: 07:37:53 ~ 65m 47s (- 59m 31s) (105 52%) AVG: 6.0394 Total: 95332.4654\n",
            "Current Time: 07:37:53 ~ 65m 47s (- 59m 31s) (105 52%) AVG: 6.0394 Total: 95332.4654\n",
            "Current Time: 07:41:10 ~ 69m 4s (- 56m 30s) (110 55%) AVG: 6.1975 Total: 97827.1536\n",
            "Current Time: 07:41:10 ~ 69m 4s (- 56m 30s) (110 55%) AVG: 6.1975 Total: 97827.1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2766bpqOarRP",
        "outputId": "5311d5fe-afd8-4874-f0ab-87ec9488af11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "import time\n",
        "\n",
        "t = time.localtime()\n",
        "current_time = time.strftime(\"%H:%M:%S\", t)\n",
        "print('Current time: %s'%(current_time) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current time: 07:54:17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUq24qN2hm_Q",
        "outputId": "356fdd41-c8af-479c-c148-149e71e291a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def GetFileChar():\n",
        "  file = open(main_directory+'break.txt')\n",
        "  lines = file.readlines()\n",
        "  return lines[0].strip()\n",
        "\n",
        "q = GetFileChar()\n",
        "if q == 'c':\n",
        "  print('as')\n",
        "else:\n",
        "  print(q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw95yiFMRLh6"
      },
      "source": [
        "def GetEncodedVector(encoder, sentence):\n",
        "  with torch.no_grad():\n",
        "    sentence_tensor = tensorFromSentence(input_words, sentence)\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder.initCellState()\n",
        "    input_length = sentence_tensor.size(0)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "          sentence_tensor[ei], encoder_hidden, encoder_cell)\n",
        "  return encoder_hidden, encoder_cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHM3Ix5cnGqy"
      },
      "source": [
        "def evaluate(decoder, context_hid, context_cell, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "    decoder_hidden = context_hid\n",
        "    decoder_cell = context_cell\n",
        "\n",
        "    decoded_words = []\n",
        "    # decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "          decoder_input, decoder_hidden, decoder_cell)\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      if topi.item() == EOS_token or topi.item() == SOS_token:\n",
        "        # decoded_words.append('EOS')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(input_words.index2word[topi.item()])\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZwC79Ckt1iQ"
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "def GetContext(encoder, sentences, query_word):\n",
        "  qw_hidden,qw_cell = GetEncodedVector(encoder, query_word)\n",
        "  if sentences == []:\n",
        "    return qw_hidden, qw_cell\n",
        "  qw_hidden = qw_hidden.cpu().numpy()\n",
        "  qw_cell = qw_cell.cpu().numpy()\n",
        "  sen_hiddens = []\n",
        "  sen_cells = []\n",
        "  for sentence in sentences:\n",
        "    sen_hid, sen_cell = GetEncodedVector(encoder, sentence)\n",
        "    sen_hiddens.append(sen_hid.cpu().numpy() )\n",
        "    sen_cells.append(sen_cell.cpu().numpy() )\n",
        "  sen_hiddens = np.array(sen_hiddens)\n",
        "  sen_cells = np.array(sen_cells)\n",
        "  weights_hid = []\n",
        "  weights_cell = []\n",
        "  for sen_hidden in sen_hiddens:\n",
        "    # print(type())\n",
        "    dist = spatial.distance.cosine(sen_hidden, qw_hidden)\n",
        "    weights_hid.append(np.array([dist]))\n",
        "  for sen_cell in sen_cells:\n",
        "    dist = spatial.distance.cosine(sen_cell, qw_cell)\n",
        "    weights_cell.append(np.array([dist]))\n",
        "\n",
        "  weights_hid = np.array(weights_hid/max(weights_hid)).reshape(-1,1,1,1)\n",
        "  weights_cell = np.array(weights_cell/max(weights_cell)).reshape(-1,1,1,1)\n",
        "  # print(sen_hiddens.shape)\n",
        "  context_hid = np.average(weights_hid * sen_hiddens, axis = 0)\n",
        "  context_cell = np.average(weights_cell * sen_cells, axis = 0)\n",
        "  # print(weights.shape)\n",
        "  # print(context.shape)\n",
        "  context_hid = torch.from_numpy(context_hid).to(device)\n",
        "  context_cell = torch.from_numpy(context_cell).to(device)\n",
        "  # print(context.size())\n",
        "  return context_hid, context_cell\n",
        "\n",
        "def GetContext_P(sequences, query_word):\n",
        "  qw_embed = weights_matrix[input_words.word2index[query_word]].cpu().numpy()\n",
        "  if sequences == []:\n",
        "    return qw_embed\n",
        "  seq_embeddings = []\n",
        "  for sequence in sequences:\n",
        "    seq_embed = np.zeros((1, emb_dim))\n",
        "    sequence = sequence.split(' ')\n",
        "    for word in sequence:\n",
        "      seq_embed += weights_matrix[input_words.word2index[word]].cpu().numpy()\n",
        "    seq_embeddings.append(seq_embed)\n",
        "  seq_embeddings = np.array(seq_embeddings)\n",
        "  \n",
        "  weights = []\n",
        "  for seq_embed in seq_embeddings:\n",
        "      # get the distance between the query word and the sentence embeddings\n",
        "      print(seq_embed.shape)\n",
        "      print(qw_embed.shape)\n",
        "      dist = spatial.distance.cosine(seq_embed, qw_embed)\n",
        "      weights.append(np.array([dist]))\n",
        "      \n",
        "  # normalize the distances\n",
        "  weights = np.array(weights/max(weights))\n",
        "      \n",
        "  # get the final weighted context\n",
        "  context = sum(weights * seq_embeddings)\n",
        "  context = torch.from_numpy(context).to(device)\n",
        "  print(type(context))\n",
        "  return context\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7xd5qrxojL6",
        "outputId": "34210fc9-de6f-4650-8594-f122b5de041c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def GeneratePoem(encoder, decoder, query_word, nLines=10):\n",
        "  output_sentences = []\n",
        "  for i in range(nLines):\n",
        "      context_hid, context_cell = GetContext(encoder, output_sentences[-5:], query_word)\n",
        "      # context = torch.from_numpy(context).to(device)\n",
        "      # print(type(context))\n",
        "      output_words = evaluate(decoder, context_hid, context_cell)\n",
        "      output_sentence = ' '.join(output_words)\n",
        "      output_sentences.append(output_sentence)\n",
        "      print(output_sentence)\n",
        "\n",
        "hidden_size = 200\n",
        "\n",
        "encoder = EncoderRNN(input_words.n_words, hidden_size, weights_matrix).to(device)\n",
        "decoder = DecoderRNN(hidden_size, input_words.n_words, weights_matrix).to(device)\n",
        "model_name= 'h200_ep_200.pt'\n",
        "\n",
        "encoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/enc_'+model_name))\n",
        "decoder.load_state_dict(torch.load(main_directory+'SavedPoemModels/dec_'+model_name))\n",
        "\n",
        "GeneratePoem(encoder, decoder, 'limb')      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35785d0e9ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'h200_ep_200.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EncoderRNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Oqa_VZuQr1",
        "outputId": "e641c585-fc86-455f-d753-df96253b5cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sequences = ['sky', 'sky love']\n",
        "query_word = 'love'\n",
        "context = GetContext(encoder, sequences, query_word)\n",
        "print(type(context))\n",
        "print(context.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 1, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNFtrux2aM4d",
        "outputId": "abd660f8-8674-4070-f90b-5d4c0111cef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "w = np.array([[1],[2]])\n",
        "w = np.array(w/max(w))\n",
        "w = np.reshape(w,(-1,1,1,1))\n",
        "print(w.shape)\n",
        "print(w)\n",
        "q = np.ones((2,1,1,3))\n",
        "print(q)\n",
        "print(w.shape)\n",
        "result = np.multiply(w,q)\n",
        "print(result.shape)\n",
        "print(result)\n",
        "result = np.average(w*q,axis = 0)\n",
        "print(\"\\nResult:\")\n",
        "# print(result)\n",
        "print(result.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bfdc18b96cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtvS7reOr1DT",
        "outputId": "1208a7ec-04f4-4ce4-86db-6c6e39276f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = [1,2,3,4,5,6,7]\n",
        "print(s[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdrlGZY9yFNq",
        "outputId": "a68fddae-6e14-45d7-bb24-2a0480c2d20d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "start_sentence = \"From fairest creatures we\"\n",
        "GeneratePoem(encoder, decoder, normalizeString(start_sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from fairest creatures we\n",
            "we fear we rich we ever fear breast breast breast\n",
            "pluck fed fed whereupon pluck or fed ?\n",
            "to makes makes to breach to makes .\n",
            "to wail to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n",
            "to mingle to to to to to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHlbnKwwjkXd"
      },
      "source": [
        "def get_context(sequences, query_word):\n",
        "  \"\"\"\n",
        "    This function takes as input multiple lines generated by the model so far and a query_word or the theme of the poem.\n",
        "    \n",
        "    So, the approach is we will add the embeddings of all the words in a sentence to get the sentence embeddings and will\n",
        "    create the sentence embeddings for all the sentences created so far.\n",
        "    \n",
        "    Now, to summarize all the sentence embeddings into a single vector, we will calculate the distance of all the sentence\n",
        "    from the query_word. These weights are normalized and will be used as the weights to combine the sentence embeddings.\n",
        "    \n",
        "    This final embedding vector or the context will be passed to the Decoder as a hidden state and a new line is generated from it.\n",
        "  \"\"\"\n",
        "  \n",
        "  assert query_word in sg_obj.word2idx\n",
        "  \n",
        "  # null vector containing all zeroes\n",
        "  query_word_embed = sg_obj.word2vec.get(query_word, np.zeros(shape=(EMBEDDING_DIM)))\n",
        "  \n",
        "  if sequences == []:\n",
        "      return query_word_embed\n",
        "  \n",
        "  # to keep all the sentence embeddings\n",
        "  seq_embeddings = []\n",
        "  for seq in sequences:  \n",
        "    # add up all the word embeddings of a sequence\n",
        "    zero_vector = np.zeros(shape=(EMBEDDING_DIM))\n",
        "    for word in seq:\n",
        "        zero_vector += sg_obj.word2vec.get(word, np.zeros(shape=(EMBEDDING_DIM)))\n",
        "    seq_embeddings.append(zero_vector)\n",
        "  seq_embeddings = np.array(seq_embeddings)\n",
        "          \n",
        "  weights = []\n",
        "  for seq_embed in seq_embeddings:\n",
        "      # get the distance between the query word and the sentence embeddings\n",
        "      dist = spatial.distance.cosine(seq_embed, query_word_embed)\n",
        "      weights.append(np.array([dist]))\n",
        "      \n",
        "  # normalize the distances\n",
        "  weights = np.array(weights/max(weights))\n",
        "      \n",
        "  # get the final weighted context\n",
        "  context = sum(weights * seq_embeddings)\n",
        "  \n",
        "  return context\n",
        "\n",
        "def get_sample_line(context):\n",
        "  \"\"\"\n",
        "      Get a single line using the provided context as a hidden state\n",
        "      \n",
        "      Parameters:\n",
        "          context (np.array): generated context of the same size as the word_embedding\n",
        "  \"\"\"\n",
        "  \n",
        "  # sentence start token\n",
        "  sos_token = np.array([[sg_obj.word2idx.get(\"<sos>\")]])\n",
        "  \n",
        "  # create the empty lstm state vectors\n",
        "  h = np.array([context])    \n",
        "  c = np.zeros(shape=(1, LATENT_DIM))\n",
        "  \n",
        "  # so we know when to quit\n",
        "  eos_token = sg_obj.word2idx['<eos>']\n",
        "  \n",
        "  output_sequence = []\n",
        "  \n",
        "  # limit the length of the generated line\n",
        "  for i in range(sg_obj.MAX_SEQ_LEN):\n",
        "      \n",
        "      # predict the first word\n",
        "      # the outputed stated are passed to the lstm to generate the next word in the sequence\n",
        "      o, h, c = Decoder.predict([sos_token, h, c])\n",
        "      \n",
        "      # get the probabilities generated from the dense layer\n",
        "      probs = o[0,0]\n",
        "      \n",
        "      if np.argmax(probs) ==0:\n",
        "          print(\"Something went wrong!!\")\n",
        "      \n",
        "      probs = np.nan_to_num(probs)\n",
        "      # the word-indices starts from 1 so 1st value does not count\n",
        "      probs[0] = 0 \n",
        "      \n",
        "      # normalize the probabilities\n",
        "      probs /= probs.sum()\n",
        "      \n",
        "      # select a random word with provided probability of being selected\n",
        "      selected_idx = np.random.choice(len(probs), p=probs)\n",
        "      \n",
        "      # if the generated word is equal to eos_token, terminate\n",
        "      if selected_idx == eos_token:\n",
        "          break\n",
        "      \n",
        "      # append the generated word to the output_sequence\n",
        "      output_sequence.append(sg_obj.idx2word.get(selected_idx, \"Error <%d>\" % selected_idx))\n",
        "      \n",
        "      # the word generated will be used as an input to generated the new word\n",
        "      sos_token[0][0] = selected_idx\n",
        "  \n",
        "  # return the sequence\n",
        "  return output_sequence    \n",
        "\n",
        "################### MAIN ################\n",
        "# the theme of the poem - only single word (for simplicity)\n",
        "query_word = \"love\"\n",
        "\n",
        "# to append the generated poem lines\n",
        "poem_lines = []\n",
        "\n",
        "# first sequence containing only ones, this will be used to generate the context\n",
        "sequences = []\n",
        "\n",
        "# we will be generating 8 lines, you can play around with this\n",
        "for line_no in range(8):\n",
        "    \n",
        "    # get the context, for the first line the context will contain the embeddings of the theme words itself\n",
        "    context = get_context(sequences, query_word)\n",
        "    \n",
        "    try:\n",
        "        # generate a new line and append it\n",
        "        sequences.append(get_sample_line(context))\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    poem_lines.append(\" \".join(sequences[-1]))\n",
        "    \n",
        "print(\"\\n\\n\")\n",
        "print(\"\\n\".join(poem_lines))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBxtT-N_z4OO"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRHxZ3UgoSck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}